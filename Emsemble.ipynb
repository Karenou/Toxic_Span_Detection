{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emsemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiBPfdlxSxDL",
        "outputId": "386adddf-1800-467f-9e57-45ba430731e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_result(file_path):\n",
        "  results = []\n",
        "  with open(file_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      result_str = line.split(\",\")[:-1]\n",
        "      result_int = []\n",
        "      for tag in result_str:\n",
        "        result_int.append(int(tag))\n",
        "      results.append(result_int)\n",
        "  return results\n",
        "\n",
        "def load_result_2(file_path):\n",
        "  results = []\n",
        "  with open(file_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      result_str = line.replace(\"\\\"\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\", \"\").split(\",\")\n",
        "      result_int = []\n",
        "      for tag in result_str:\n",
        "        if tag != \"\":\n",
        "          result_int.append(int(tag))\n",
        "      results.append(result_int)\n",
        "  return results"
      ],
      "metadata": {
        "id": "2M9S1raZX7m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = load_result(\"/content/drive/My Drive/5018_ToxicSpans/label_files/bert.csv\")\n",
        "bert_avg = load_result(\"/content/drive/My Drive/5018_ToxicSpans/label_files/bert_avg.csv\")\n",
        "bert_lstm = load_result(\"/content/drive/My Drive/5018_ToxicSpans/label_files/bert_lstm.csv\")\n",
        "bert_pseudo = load_result(\"/content/drive/My Drive/5018_ToxicSpans/label_files/bert_pseudo.csv\")\n",
        "flair = load_result_2(\"/content/drive/My Drive/5018_ToxicSpans/label_files/flair.txt\")\n",
        "fasttext = load_result_2(\"/content/drive/My Drive/5018_ToxicSpans/label_files/fasttext.txt\")\n",
        "\n",
        "# # Note:\n",
        "# # flair.txt is renamed from /pred_result/flair_forweard_pred.csv and the first line is removed.\n",
        "# # fasttext.txt is renamed from /pred_result/ft_pred.csv and the first line is removed."
      ],
      "metadata": {
        "id": "wBBqeq5yYiH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title fix spans { form-width: \"1px\" }\n",
        "import itertools\n",
        "import string \n",
        "import csv\n",
        "import ast\n",
        "\n",
        "SPECIAL_CHARACTERS = string.whitespace\n",
        "\n",
        "def _contiguous_ranges(span_list):\n",
        "    \"\"\"Extracts continguous runs [1, 2, 3, 5, 6, 7] -> [(1,3), (5,7)].\"\"\"\n",
        "    output = []\n",
        "    for _, span in itertools.groupby(\n",
        "        enumerate(span_list), lambda p: p[1] - p[0]):\n",
        "        span = list(span)\n",
        "        output.append((span[0][1], span[-1][1]))\n",
        "    return output\n",
        "\n",
        "def fix_spans(spans, text, special_characters=SPECIAL_CHARACTERS):\n",
        "    \"\"\"Applies minor edits to trim spans and remove singletons.\"\"\"\n",
        "    cleaned = []\n",
        "    for begin, end in _contiguous_ranges(spans):\n",
        "        while text[begin] in special_characters and begin < end:\n",
        "            begin += 1\n",
        "        while text[end] in special_characters and begin < end:\n",
        "            end -= 1\n",
        "        if end - begin > 1:\n",
        "            cleaned.extend(range(begin, end + 1))\n",
        "    return cleaned\n",
        "\n",
        "def read_datafile(filename):\n",
        "  \"\"\"Reads csv file with python span list and text.\"\"\"\n",
        "  data = []\n",
        "  with open(filename) as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    count = 0\n",
        "    for row in reader:\n",
        "      fixed = fix_spans(\n",
        "          ast.literal_eval(row['spans']), row['text'])\n",
        "      data.append((fixed, row['text']))\n",
        "  return data\n",
        "\n",
        "test= read_datafile('/content/drive/My Drive/5018_ToxicSpans/datasets/tsd_test.csv')\n",
        "true_labels = []\n",
        "for i in range(len(test)):\n",
        "  true_labels.append(test[i][0])"
      ],
      "metadata": {
        "id": "oO9nCJCib0zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def f1(predictions, gold):\n",
        "  if len(gold) == 0:\n",
        "    return 1. if len(predictions) == 0 else 0.\n",
        "  if len(predictions) == 0:\n",
        "    return 0.\n",
        "  predictions_set = set(predictions)\n",
        "  gold_set = set(gold)\n",
        "  nom = 2 * len(predictions_set.intersection(gold_set))\n",
        "  denom = len(predictions_set) + len(gold_set)\n",
        "  return float(nom)/float(denom)\n",
        "\n",
        "pred_labels = []\n",
        "for i in range(len(bert)):\n",
        "  labels = []\n",
        "  tmp = []\n",
        "  # tmp.extend(bert[i])\n",
        "  # tmp.extend(bert_pseudo[i])\n",
        "  # tmp.extend(bert_avg[i])\n",
        "  # tmp.extend(bert_lstm[i])\n",
        "  # tmp.extend(fasttext[i])\n",
        "  tmp.extend(flair[i])\n",
        "  \n",
        "  set_tag = set(tmp)\n",
        "\n",
        "  # # vote (>50%)\n",
        "  # for tag in set_tag:\n",
        "  #   if tmp.count(tag) > 1:\n",
        "  #     labels.append(tag)\n",
        "\n",
        "  # # union\n",
        "  # labels = list(set_tag)\n",
        "\n",
        "  # intersection\n",
        "  for tag in set_tag:\n",
        "    if tmp.count(tag) > 0:\n",
        "      labels.append(tag)\n",
        "\n",
        "  pred_labels.append(labels)\n",
        "\n",
        "scores = [] \n",
        "for i in range(len(true_labels)):\n",
        "  scores.append(f1(pred_labels[i], true_labels[i]))\n",
        "scores = np.mean(scores)\n",
        "print(\"test f1: {}\".format(scores * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MP-UjjXchrG",
        "outputId": "a13d91e8-430d-4702-e8c3-5f83c9871b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test f1: 65.50818381917338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # best 68.43:\n",
        "# intersection(bert_avg, bert_lstm, fasttext, flair)"
      ],
      "metadata": {
        "id": "rmHtEhPcitQJ"
      }
    }
  ]
}